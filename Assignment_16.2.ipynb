{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b41edf-5c8a-4032-b457-95875da0151a",
   "metadata": {},
   "source": [
    "### Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458661f-e1e4-4bed-9609-5efab66e4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Display summary statistics of the dataset\n",
    "print(data.describe())\n",
    "\n",
    "# Plot histograms for numeric variables\n",
    "numeric_vars = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "data[numeric_vars].hist(bins=20, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot a correlation heatmap\n",
    "corr_matrix = data.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to visualize relationships between variables\n",
    "sns.pairplot(data, hue='Outcome', diag_kind='kde')\n",
    "plt.show()\n",
    "# Make sure to replace 'diabetes.csv' with the actual path to your dataset file. This code will help you load the dataset, display the first few rows, show summary statistics, plot histograms, visualize correlations, and create a pair plot to observe relationships between variables, differentiated by the outcome classes.\n",
    "\n",
    "# This exploratory data analysis will provide insights into the distribution of variables and potential relationships between them, which will be helpful for building a decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f999d67-7ce4-4371-a0ef-28a6cfc589f2",
   "metadata": {},
   "source": [
    "### Question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36f464-f8d2-49c9-9311-0589da53382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Handling missing values\n",
    "# Replace 0 values with NaN for relevant columns\n",
    "cols_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "data[cols_with_zeros] = data[cols_with_zeros].replace(0, pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Removing outliers\n",
    "# You can use different methods to detect and remove outliers\n",
    "# Here's an example using z-score\n",
    "from scipy.stats import zscore\n",
    "z_scores = zscore(data[numeric_vars])\n",
    "outliers = (z_scores > 3).any(axis=1)\n",
    "data = data[~outliers]\n",
    "\n",
    "# Transform categorical variables into dummy variables\n",
    "# Assuming 'Pregnancies' might be considered categorical\n",
    "data = pd.get_dummies(data, columns=['Pregnancies'], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the preprocessed dataset\n",
    "print(data.head())\n",
    "# In this code, I've handled missing values by replacing 0 values with NaN and then dropping rows with missing values. I've used the Z-score method to detect and remove outliers, and I've transformed the categorical variable 'Pregnancies' into dummy variables using the pd.get_dummies() function.\n",
    "\n",
    "# Please replace 'diabetes.csv' with the actual path to your dataset file and adjust the code as needed for your specific preprocessing requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad4586-caf8-4750-8ac5-da9583cd3e39",
   "metadata": {},
   "source": [
    "### Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea47f2c-4087-48a8-9e1f-5d235f454d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('preprocessed_diabetes.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Display the shape of the training and test sets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "#Replace 'preprocessed_diabetes.csv' with the actual path to your preprocessed dataset file. The code will split the data into features and target, then further split it into training and test sets using a random seed of 42 for reproducibility. You can adjust the test_size parameter to control the proportion of data allocated for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469324ae-bfb0-4ffa-8759-848d9b5883f8",
   "metadata": {},
   "source": [
    "### Question4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884be98-dc47-45ee-892c-36132e39064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('preprocessed_diabetes.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# Define a range of hyperparameters to tune\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the corresponding model\n",
    "best_params = grid_search.best_params_\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = best_dt_model.score(X_test, y_test)\n",
    "print(\"Test set accuracy:\", accuracy)\n",
    "# In this code, we use a Decision Tree classifier and perform grid search cross-validation to find the best hyperparameters for the model. The param_grid dictionary defines a range of hyperparameters to be tuned. The best hyperparameters are then used to evaluate the model's performance on the test set.\n",
    "\n",
    "# Replace 'preprocessed_diabetes.csv' with the actual path to your preprocessed dataset file. You can adjust the hyperparameter ranges in the param_grid dictionary based on your preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f243402-2e06-46f9-8c00-97f631c11bcc",
   "metadata": {},
   "source": [
    "### Question5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329d2d6-7c9e-4d6a-8a87-9dd20614b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('preprocessed_diabetes.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "y_prob = dt_classifier.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xticks([0, 1], ['Non-Diabetic', 'Diabetic'])\n",
    "plt.yticks([0, 1], ['Non-Diabetic', 'Diabetic'])\n",
    "plt.show()\n",
    "# In this code, we calculate metrics such as accuracy, precision, recall, and F1 score using Scikit-learn's metrics functions. We also calculate the ROC curve and AUC using the roc_curve and roc_auc_score functions. Then, we plot the ROC curve and confusion matrix to visualize the model's performance.\n",
    "\n",
    "# Replace 'preprocessed_diabetes.csv' with the actual path to your preprocessed dataset file. The code provided will help you evaluate and visualize the performance of the Decision Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4292cf-bd8f-4312-bd8f-328511762bf6",
   "metadata": {},
   "source": [
    "### Question6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2abd7c-2d5b-477f-99ad-6c1d7c6a587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Interpretation:\n",
    "\n",
    "# The Decision Tree consists of multiple splits, each dividing the data into subsets based on specific variables and thresholds.\n",
    "\n",
    "#1. The root node's split is based on the \"Glucose\" variable with a threshold of 127.5. If a patient's plasma glucose concentration is less than or equal to 127.5, the model moves to the left branch. Otherwise, it moves to the right branch.\n",
    "\n",
    "#2. In the left branch, the next split occurs based on the \"BMI\" variable with a threshold of 26.9. If a patient's BMI is less than or equal to 26.9, the model moves further down the left branch. Otherwise, it moves down the right branch.\n",
    "\n",
    "#3. In the left-left branch, the Decision Tree looks at the \"Age\" variable with a threshold of 33.5. If a patient's age is less than or equal to 33.5, the model predicts \"Non-Diabetic\" (class 0). If the age is greater than 33.5, the model predicts \"Diabetic\" (class 1).\n",
    "\n",
    "#4. In the left-right branch, the Decision Tree considers the \"Pregnancies\" variable with a threshold of 6.5. If a patient has fewer than or equal to 6.5 pregnancies, the model predicts \"Non-Diabetic.\" If the patient has more than 6.5 pregnancies, the model predicts \"Diabetic.\"\n",
    "\n",
    "#5. The right branch of the root node (when glucose > 127.5) leads to predictions based on different features.\n",
    "\n",
    "#The important variables are \"Glucose,\" \"BMI,\" \"Age,\" and \"Pregnancies.\" These variables are crucial in determining whether a patient is likely to be diabetic or not.\n",
    "\n",
    "#Interpretation Summary:\n",
    "\n",
    "#The Decision Tree model makes predictions based on several clinical variables, with \"Glucose,\" \"BMI,\" \"Age,\" and \"Pregnancies\" being the most important features. It uses thresholds on these variables to create branches and make predictions. The Decision Tree's structure reflects patterns and relationships within the data, providing insights into how these features contribute to diabetes prediction.\n",
    "\n",
    "# Keep in mind that the interpretation provided is based on a hypothetical scenario. In practice, it's important to closely analyze the actual Decision Tree structure and consider domain knowledge to ensure accurate interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe14ec-70f4-43f0-86ee-5e68f0ce6db1",
   "metadata": {},
   "source": [
    "### Question7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bf13c-ec6d-43ec-af6a-d302be012ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating a decision tree model involves testing its performance on new data or assessing its robustness to various changes. Sensitivity analysis and scenario testing can help explore uncertainties and potential risks. Here's how you can validate the decision tree model for the diabetes prediction task:\n",
    "\n",
    "#    New Data Testing:\n",
    "#    Gather additional data that was not used during model training and evaluate the model's performance on this new data. This provides a measure of how well the model generalizes to unseen examples.\n",
    "\n",
    "#    Cross-Validation:\n",
    "#    Perform cross-validation on the training dataset to assess the model's stability and performance across different subsets of data. This helps ensure that the model is not overfitting to specific parts of the data.\n",
    "\n",
    "#    Robustness Testing:\n",
    "#    Introduce small perturbations or noise to the features in the dataset and observe how the model's predictions change. A robust model should not be overly sensitive to small variations in the input data.\n",
    "\n",
    "#    Scenario Testing:\n",
    "#    Test the model's performance on different scenarios that may arise in real-world situations. For instance, simulate cases where some features are missing, or when the distribution of certain features changes. This helps uncover how the model performs under varying conditions.\n",
    "\n",
    "#    Sensitivity Analysis:\n",
    "#    Conduct sensitivity analysis by modifying the model's hyperparameters or parameters and observing how it affects the model's predictions. This helps identify how sensitive the model is to changes and if certain settings lead to better or worse performance.\n",
    "\n",
    "#    Feature Importance Validation:\n",
    "#    Confirm the importance of features identified by the decision tree by testing the model's performance when certain features are excluded or varied. This ensures that the model's decisions are consistent with domain knowledge.\n",
    "\n",
    "#    A/B Testing:\n",
    "#    If possible, conduct A/B testing where you compare the decisions made by the decision tree model against other methods or human experts. This helps validate whether the model's predictions lead to better outcomes.\n",
    "\n",
    "#    Domain Expert Review:\n",
    "#    Collaborate with domain experts to validate the model's predictions and interpretations. Their input can provide valuable insights and ensure that the model aligns with medical knowledge.\n",
    "\n",
    "#By performing these validation steps, you can gain a deeper understanding of the decision tree model's performance, its robustness, and how it behaves in different scenarios. This information is crucial for making informed decisions about deploying the model in real-world applications and understanding its limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
