{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e29ab13-6ed5-460a-a00c-4ea6783d265f",
   "metadata": {},
   "source": [
    "### Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88265e-5a81-475c-8462-0338b8afb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python code example that implements the K-Nearest Neighbors (KNN) classifier algorithm using the load_iris dataset from scikit-learn:\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with a chosen value of K\n",
    "k = 3  # You can change this value\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy of KNN Classifier with K={k}: {accuracy}')\n",
    "\n",
    "# In this code:\n",
    "\n",
    "#    We import the necessary libraries, including load_iris for loading the dataset, KNeighborsClassifier for creating the KNN classifier, and train_test_split for splitting the data into training and testing sets.\n",
    "\n",
    "#    We load the iris dataset and separate the features (X) and the target variable (y).\n",
    "\n",
    "#    We split the dataset into training and testing sets using train_test_split, with 70% of the data used for training and 30% for testing.\n",
    "\n",
    "#    We initialize the KNN classifier with a chosen value of K (you can change the k variable to experiment with different values).\n",
    "\n",
    "#    The model is trained on the training data using fit.\n",
    "\n",
    "#    We make predictions on the test data using predict.\n",
    "\n",
    "#    Finally, we calculate the accuracy of the KNN classifier on the test data and print the result.\n",
    "\n",
    "# You can change the value of k to see how it affects the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8c221-e268-490c-b4d6-89bd8e732b5a",
   "metadata": {},
   "source": [
    "### Question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452c9ad-b58b-4c4f-a99e-9ffe23c7dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python code example that implements the K-Nearest Neighbors (KNN) regressor algorithm using the load_boston dataset from scikit-learn:\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data  # Features\n",
    "y = boston.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN regressor with a chosen value of K\n",
    "k = 3  # You can change this value\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) and R-squared (R2) score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'R-squared (R2) Score: {r2:.2f}')\n",
    "\n",
    "# In this code:\n",
    "\n",
    "#    We import the necessary libraries, including load_boston for loading the dataset, KNeighborsRegressor for creating the KNN regressor, and train_test_split for splitting the data into training and testing sets.\n",
    "\n",
    "#    We load the Boston Housing dataset and separate the features (X) and the target variable (y).\n",
    "\n",
    "#    We split the dataset into training and testing sets using train_test_split, with 70% of the data used for training and 30% for testing.\n",
    "\n",
    "#    We initialize the KNN regressor with a chosen value of K (you can change the k variable to experiment with different values).\n",
    "\n",
    "#    The model is trained on the training data using fit.\n",
    "\n",
    "#    We make predictions on the test data using predict.\n",
    "\n",
    "#    Finally, we calculate the Mean Squared Error (MSE) and R-squared (R2) score to evaluate the performance of the KNN regressor.\n",
    "\n",
    "# You can change the value of k to see how it affects the regression performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15241e4-8302-4996-ba99-20389fc29012",
   "metadata": {},
   "source": [
    "#### Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccdfc7-36c8-41e1-ad49-f1271c2edfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the optimal value of K for the K-Nearest Neighbors (KNN) classifier using cross-validation on the load_iris dataset from scikit-learn, you can perform a grid search over different values of K and select the one with the best cross-validated performance. Here's a Python code snippet to do that:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (optional)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a range of K values to try\n",
    "k_values = list(range(1, 21))  # You can adjust this range\n",
    "\n",
    "# Create an empty list to store cross-validated accuracy scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation for each K value\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Plot the cross-validated accuracy scores for different K values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, cv_scores, marker='o', linestyle='-', color='b')\n",
    "plt.title('Cross-Validated Accuracy vs. K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal K value with the highest accuracy\n",
    "optimal_k = k_values[np.argmax(cv_scores)]\n",
    "print(f'Optimal K value: {optimal_k}')\n",
    "\n",
    "# In this code:\n",
    "\n",
    "#    We load the Iris dataset and separate the features (X) and the target variable (y).\n",
    "\n",
    "#    Optionally, you can split the dataset into training and testing sets using train_test_split. This step is not necessary if you intend to use cross-validation for model evaluation.\n",
    "\n",
    "#    We define a range of K values to try (in this example, from 1 to 20). You can adjust this range based on your preferences.\n",
    "\n",
    "#    We create an empty list, cv_scores, to store the cross-validated accuracy scores for different K values.\n",
    "\n",
    "#    We perform k-fold cross-validation for each K value and compute the mean accuracy score using cross_val_score.\n",
    "\n",
    "#    The cross-validated accuracy scores are plotted against the K values to help you visually identify the optimal K value.\n",
    "\n",
    "#    Finally, we find and print the optimal K value with the highest cross-validated accuracy.\n",
    "\n",
    "# This code will help you determine the best K value for your KNN classifier on the Iris dataset using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055a952-36f5-4756-80cb-b593a20b87a2",
   "metadata": {},
   "source": [
    "#### Question4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e282b-3a6a-435c-8fdf-b8ac3263eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python code snippet to implement the K-Nearest Neighbors (KNN) regressor algorithm with feature scaling on the load_boston dataset from scikit-learn:\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data  # Features\n",
    "y = boston.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN regressor model\n",
    "k = 5  # Number of neighbors (you can adjust this)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2) Score: {r2}\")\n",
    "\n",
    "#In this code:\n",
    "#\n",
    "#    We load the Boston Housing dataset and separate the features (X) and the target variable (y).\n",
    "\n",
    "#    We split the dataset into training and testing sets using train_test_split, with 80% of the data for training and 20% for testing.\n",
    "\n",
    "#    We standardize the features using StandardScaler to ensure that each feature has a mean of 0 and a standard deviation of 1. This step is essential for KNN as it relies on distance metrics.\n",
    "\n",
    "#    We create a KNN regressor model with the desired number of neighbors (in this case, k = 5), but you can adjust this value based on your needs.\n",
    "\n",
    "#    The KNN regressor is fitted to the training data.\n",
    "\n",
    "#    We make predictions on the test data using the trained model.\n",
    "\n",
    "#    Finally, we evaluate the model's performance using mean squared error (MSE) and R-squared (R2) score, which are common metrics for regression tasks.\n",
    "\n",
    "# This code demonstrates how to implement KNN regression with feature scaling on the Boston Housing dataset. You can adjust the value of k and other parameters as needed for your specific regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34fdb0-70bb-42d8-8e9b-82d07c0b44eb",
   "metadata": {},
   "source": [
    "### Question5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f418fe-94bb-4297-a11f-2cdb2a77dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python code snippet to implement the K-Nearest Neighbors (KNN) classifier algorithm with weighted voting on the load_iris dataset from scikit-learn:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN classifier model with weighted voting\n",
    "k = 5  # Number of neighbors (you can adjust this)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# In this code:\n",
    "\n",
    "#    We load the Iris dataset and separate the features (X) and the target variable (y).\n",
    "\n",
    "#    We split the dataset into training and testing sets using train_test_split, with 80% of the data for training and 20% for testing.\n",
    "\n",
    "#    We standardize the features using StandardScaler to ensure that each feature has a mean of 0 and a standard deviation of 1. Standardization is essential for KNN as it relies on distance metrics.\n",
    "\n",
    "#    We create a KNN classifier model with the desired number of neighbors (in this case, k = 5) and specify weights='distance' to enable weighted voting based on the inverse of the distances.\n",
    "\n",
    "#    The KNN classifier is fitted to the training data.\n",
    "\n",
    "#    We make predictions on the test data using the trained model.\n",
    "\n",
    "#    Finally, we evaluate the model's performance using accuracy, a common metric for classification tasks.\n",
    "\n",
    "# This code demonstrates how to implement KNN classification with weighted voting on the Iris dataset. You can adjust the value of k and other parameters as needed for your specific classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce3262-5d1a-4935-9721-d49904bc00c7",
   "metadata": {},
   "source": [
    "### Question6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13731a-adff-4f6e-9b25-7a83108971a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python function that standardizes the features using StandardScaler from scikit-learn before applying a KNN classifier:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training data features\n",
    "    - X_test: Testing data features\n",
    "\n",
    "    Returns:\n",
    "    - X_train_scaled: Standardized training data features\n",
    "    - X_test_scaled: Standardized testing data features\n",
    "    \"\"\"\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the scaler on the training data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Transform the testing data using the same scaler\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# You can use this function to standardize your training and testing data features before applying the KNN classifier. Here's how you can use it:\n",
    "\n",
    "# Assuming you have loaded and split your data into X_train, X_test, y_train, and y_test\n",
    "X_train_scaled, X_test_scaled = standardize_features(X_train, X_test)\n",
    "\n",
    "# Create and train the KNN classifier using X_train_scaled\n",
    "# Make predictions, evaluate the model, etc.\n",
    "\n",
    "# This function will ensure that your features have a mean of 0 and a standard deviation of 1, which is important for distance-based algorithms like KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f828c-cada-45f5-ba45-a5925ec5edac",
   "metadata": {},
   "source": [
    "### Question7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9df70-0cde-4ffe-8197-a806170faab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python function to calculate the Euclidean distance between two points represented as NumPy arrays:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: NumPy array representing the first point\n",
    "    - point2: NumPy array representing the second point\n",
    "\n",
    "    Returns:\n",
    "    - distance: Euclidean distance between the two points\n",
    "    \"\"\"\n",
    "    # Ensure that both points have the same dimensionality\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Both points must have the same dimensionality\")\n",
    "\n",
    "    # Calculate the Euclidean distance\n",
    "    distance = np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "    return distance\n",
    "\n",
    "# You can use this function to find the Euclidean distance between any two points by passing their coordinates as NumPy arrays. Here's an example of how to use it:\n",
    "\n",
    "point1 = np.array([1.0, 2.0, 3.0])\n",
    "point2 = np.array([4.0, 5.0, 6.0])\n",
    "\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(\"Euclidean Distance:\", distance)\n",
    "\n",
    "# This will calculate and print the Euclidean distance between point1 and point2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918c5ed-d58e-449b-835f-00a87fdfd4b3",
   "metadata": {},
   "source": [
    "### Question8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa5231-f60e-4054-b4ef-beacbb80e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Python function to calculate the Manhattan distance (also known as the L1 distance or taxicab distance) between two points represented as NumPy arrays:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: NumPy array representing the first point\n",
    "    - point2: NumPy array representing the second point\n",
    "\n",
    "    Returns:\n",
    "    - distance: Manhattan distance between the two points\n",
    "    \"\"\"\n",
    "    # Ensure that both points have the same dimensionality\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Both points must have the same dimensionality\")\n",
    "\n",
    "    # Calculate the Manhattan distance\n",
    "    distance = np.sum(np.abs(point1 - point2))\n",
    "\n",
    "    return distance\n",
    "\n",
    "# You can use this function to find the Manhattan distance between any two points by passing their coordinates as NumPy arrays. Here's an example of how to use it:\n",
    "\n",
    "point1 = np.array([1.0, 2.0, 3.0])\n",
    "point2 = np.array([4.0, 5.0, 6.0])\n",
    "\n",
    "distance = manhattan_distance(point1, point2)\n",
    "print(\"Manhattan Distance:\", distance)\n",
    "\n",
    "# This will calculate and print the Manhattan distance between point1 and point2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
